To do:


	X add use case for non-APEX apps
		if TARGET_APEX_VERSION is not defined then should we just skip all of the APEX installation/upgrade steps completely?
			YES
			X document this business rule (this would reduce the amount of time)
				If you only want a database and a database deployment service then comment out/remove the ords container in docker-compose-XX.yml
				remove TARGET_APEX_VERSION from .env
				

	X ** Update all repositories to add "containerized" to the name and use CODE as the acronym

	X Update the repo paths
	
	X Migrate to github and maintain forks
		X Pull upstream changes
	
	X Update documentation URLs
	
	X Test containers
	
	X Implement the ORDS functionality and determine what code is necessary to define ORDS endpoints
	

	_ look into the DB/APEX configuration files from DBA

	X check if the given apex version is actually available (e.g. 23.0), if not then print an error mesasge and exit with code = 1

	X update the db_app_deploy.sh code to check if the TARGET_APEX_VERSION is < the installed version and print out an error message and exit with a code = 1


X rename the docker image to have a pifsc prefix
	X pifsc/db_ords_deploy

X create a new script (custom_ prefix) to perform the actual custom db/apex deployments so it's easier to pull changes from upstream (it won't cause a conflict in the run_db_app_deployment.sh each time)


X refactor the bash functions

X create functions for validating the required environment variables





Testing:
	X test the different deployment/restart scenarios
		X dev (tested 12/2/25)
			X new deployment
				X apex
					X (error message) TARGET_APEX_VERSION invalid version (regexp validation - e.g. 24.0.0)
					X (error message) TARGET_APEX_VERSION invalid version (oracle site does not have the intaller - e.g. 24.0, 9.99)
					X valid APEX (successful and reset admin password to ${ORACLE_PWD}
						X login to workspace
					X TARGET_APEX_VERSION blank (apex is not installed)
				X db
					X login to SYS
					X login to SYSTEM
			X restart
				X change APEX version
					X TARGET_APEX_VERSION invalid version (regexp validation - e.g. 24.0.0)
					X (error message) downgrade (e.g. 23.1, 22.1)
					X (error message) TARGET_APEX_VERSION invalid version (oracle site does not have the intaller - e.g. 24.0, 9.99)
					X APEX upgrade (successful and reset admin password to ${ORACLE_PWD}
						X login to workspace
						X db
							X login to SYS
							X login to SYSTEM
					X TARGET_APEX_VERSION blank (apex is unchanged)
				X leave APEX version unchanged
					X login to workspace (password unchanged)
					X db
						X login to SYS
						X login to SYSTEM
		X test (does not save database volume) (tested 12/2/25)
			X apex
				X (error message) TARGET_APEX_VERSION invalid version (regexp validation - e.g. 24.0.0)
				X (error message) TARGET_APEX_VERSION invalid version (oracle site does not 
				X valid APEX (successful upgrade and reset admin password to ${ORACLE_PWD}
					X login to workspace
				X TARGET_APEX_VERSION blank (apex is not installed)
			X db
				X login to SYS
				X login to SYSTEM





documentation:
	X docker container configuration is defined in .env file
		image names
		oracle password (defined the same for each admin -> SYSTEM, SYS, apex internal/admin, ORDS)
		APP_SCHEMA_NAME (checked for presence to determine the database has already been deployed)
		TARGET_APEX_VERSION
		
	X document the names of each container and what their function is
	
	X ORDS config (directory is mounted in container to allow changes via repo - custom project-level settings can be saved in version control)
		X settings.xml
	
	
	How to deploy
		Clone the repo
		
		
		run the docker container (e.g. bash build_deploy_project_dev.sh)
			automatically run the prepare script (to clone all dependencies within the working directory)
				For custom data system repos add the folders (e.g. DSC, CAS, etc.) and add entries to .gitignore so they aren't added to version control

		X identify all custom scripts that will change for custom projects
			X custom_prepare_docker_project.sh
			X custom_project_config.sh
			X custom_db_app_deploy.sh
			X custom_container_config.sh
			X .env
				
		
	X update the configuration documentation for new projects (fork and customize)
	
	
		
	
	
X ** document the upstream pull process in the customization section of the documentation
	indicate which file updates to ignore (begins with custom_)
	
	X .env must be merged since each use case will define a different APP_SCHEMA_NAME value
	
	X Also document how the changes must be propagated through the fork dependency hierarchy
	
X implement the fork network in github
	It's early on so it might be best to do this sooner than later -> this could be shared with other FMCs if they are interested in a similar generalized solution
		

X update the documentation to reference the authorization key instead of logging in to oracle container registry with the username/password


X Update the versions of Oracle XE and ORDS in this repo and then allow the downstream repos to pull those changes to propagate the changes
	X dockerfile now allows .env configuration file to specify the version of oracle xe, ords, and apex





X VS Code can be used for markdown

X document the login to oracle registry

X remove traceroute from dockerfile

X update the ords-developer image (implement dockerfile) to copy the conn_string.txt file into the appropriate folder so it doesn't disappear each time the container is run
	X uses .env file instead
		X set password, ports, etc. in ENV file

X pull the upstream README.md changes into the repo



X ** ORDS_PWD environment variable for ORDS configuration?
	** Ensure that ORDS is setup correctly for those types of projects (e.g. ORDS API for web app)
	"INFO : ORDS_PWD env var is not set, using generated value"

git bash commands:

	# Dev:

		# stop and remove CODE containers and delete volumes
		cd /c/Users/jesse.abdul/Documents/Version\ Control/Git/PIFSC-Containerized-Oracle-Development-Environment
		
		docker compose \
		  --env-file ./docker/.env \
		  -f docker/CODE-db-deploy.yml \
		  -f docker/CODE-db-named-volume.yml \
		  -f docker/CODE-ords.yml \
		  -f docker/custom-docker-compose.yml \
		  down -v
		
		# build and deploy the development scenario of the CODE
		bash ./deployment_scripts/build_deploy_project.sh dev
	
	# Test:

		# stop and remove CODE containers and delete volumes
		cd /c/Users/jesse.abdul/Documents/Version\ Control/Git/PIFSC-Containerized-Oracle-Development-Environment
		
		docker compose \
		  --env-file ./docker/.env \
		  -f docker/CODE-db-deploy.yml \
		  -f docker/CODE-ords.yml \
		  -f docker/custom-docker-compose.yml \
		  down -v


		# build and deploy the test scenario of the CODE
		bash ./deployment_scripts/build_deploy_project.sh test


troubleshooting tips:
	Is the project_config.sh correct?
		Does it point at a different project_folder_name than the prepared directory?
		
		


	X Issue with the image not being able to download from the container registry
		X submit SCR to allow PIFSC network (hardwired and VPN) to access container-registry.oracle.com



	
X Provide 2 different configurations:
	X persistent data (for development sessions)
		as DB data model is adjusted during development and APEX app is being developed/adjusted/tested
	X non-persistent data (for CI/CD or testing deployment database)
	
	

X Preparation script
	X How do we leverage the existing Git projects?
		X Git clone the repo(s) and copy the SQL folder contents into appropriate subfolders (e.g. DSC, CAS, CCD, etc.)
	
	X Provide a default script (e.g. run_db_app_deployments.sh)	in the docker container that can be customized to execute specific scripts in the container
		
To do:
	Documentation:
		X How to prepare the projects
		X The requirements of any shared database schemas that need to be included in a given Oracle data system
		X How to fork and customize the project
		
	
	X build out the DSC example first
		X get an export of all objects in the DSC schema from production
	X build out the CAS example next
	_ build out the PARR Tools example next
	X Then build out the generalized upstream repo that can be forked for any given data system and that the upstream changes can be pulled moving forward
	X fork the generalized docker stack repo to create the DSC and CAS repos

	** X when we check if the schemas have been deployed, simply query to see if the expected schema exists or not, if not then run all of the deployment scripts if so just shutdown the container


	Run with database only?
		Maybe don't need that because any container scenario with an application would probably have some type of container attached to it for communication purposes
		We don't want to create every scenario of application server, it's not feasible or sensible
		
	for CI/CD purposes we would use a container with an appropriate programming language (e.g. PHP for PHPUnit)
		For testing we would want to look into PL/SQL unit testing framework so we can code coverage statistics
		
